{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8802726,"sourceType":"datasetVersion","datasetId":5293846}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"colab":{"provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["# useful libraries\n","import numpy as np\n","import pandas as pd\n","import cv2\n","from sklearn.cluster import KMeans\n","import pickle\n","from scipy.spatial.distance import cdist\n","import os\n","import glob\n","import torchvision.datasets\n","from torch.utils.data import DataLoader, Subset\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","import matplotlib.pyplot as plt"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"id":"rBl45F8QVGqd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# true labels\n","trainLabels = pd.read_csv('/kaggle/input/supervised-sets/train_labels.csv')\n","testLabels = pd.read_csv('//kaggle/input/supervised-sets/val_labels.csv')\n","\n","trainClasses = trainLabels['label'].unique()\n","testClasses = testLabels['label'].unique()"],"metadata":{"trusted":true,"id":"wc2lyBmtVGqj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# path to data\n","train_dir = '/kaggle/input/supervised-sets/processedData/processedData/processed_train_set'\n","val_dir = '/kaggle/input/supervised-sets/processedData/processedData/processed_val_set' # test directory"],"metadata":{"trusted":true,"id":"sXFZP1rlVGql"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# creation of the training set of resized images\n","size = 224\n","\n","fake_transforms = torchvision.transforms.Compose([\n","        torchvision.transforms.ToTensor(),\n","        torchvision.transforms.Resize((size, size))\n","    ])\n","\n","\n","fake_training_set = torchvision.datasets.ImageFolder(root='/kaggle/input/supervised-sets/processedData/processedData/processed_train_set', transform=fake_transforms)\n","# divide the images in batches: \"fake\" loader in order to compute mean and std for normalization\n","fake_train_loader = DataLoader(fake_training_set, batch_size=64, shuffle=True, num_workers=4)"],"metadata":{"trusted":true,"id":"t3jgn2_3VGqm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# compute the desired mean and standard deviation for the normalization\n","def tot_mean_std(loader):\n","    mean = 0\n","    std = 0\n","    count = 0\n","    for batch, _ in loader:\n","        batch_samples = batch.size(0)\n","        batch = batch.view(batch_samples, -1)\n","        # reshape to [batch_samples, 224*224]: ready to go into the SIFT feature extractor\n","        mean = mean + batch.mean(1).sum(0)  # mean over the pixels of each image of the batch summed to the others\n","        std = std + batch.std(1).sum(0)  # same for the standard deviation\n","        count = count + batch_samples\n","\n","    mean = mean/count\n","    std = std/count\n","\n","    return mean, std"],"metadata":{"trusted":true,"id":"kO8sGypjVGqo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# creation of the datasets with resized, grayscale and normalized images\n","size = 224\n","mean, std = tot_mean_std(fake_train_loader)\n","\n","transforms = torchvision.transforms.Compose([\n","        torchvision.transforms.ToTensor(),\n","        torchvision.transforms.Resize((size, size)),\n","        torchvision.transforms.Normalize(mean = mean, std = std),\n","        torchvision.transforms.Grayscale()\n","    ])\n","\n","training_set = torchvision.datasets.ImageFolder(root='/kaggle/input/supervised-sets/processedData/processedData/processed_train_set', transform=transforms)\n","test_set = torchvision.datasets.ImageFolder(root='/kaggle/input/supervised-sets/processedData/processedData/processed_test_set', transform=transforms)\n","\n","# training set reduction: get a fixed percentage from each class\n","def get_subset(data, percentage):\n","    class_indices = {}\n","    for idx, (_, label) in enumerate(data.samples):\n","        if label not in class_indices:\n","            class_indices[label] = []\n","        class_indices[label].append(idx)\n","\n","    subset_indices = []\n","    for label, indices in class_indices.items():\n","        np.random.shuffle(indices)\n","        n_subset = int(len(indices) * percentage)\n","        subset_indices.extend(indices[:n_subset])\n","\n","    return Subset(data, subset_indices)\n","\n","# grid search will be performed on 10% of the training set for computational reasons\n","subset_training = get_subset(training_set, percentage=0.1)\n","\n","\n","# \"true\" loader\n","train_loader = DataLoader(subset_training, batch_size=64, shuffle=True, num_workers=4)"],"metadata":{"trusted":true,"id":"Gq7ku26NVGqp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# extract features with SIFT\n","def sift_features(image_list):\n","    descriptors = []\n","    valid_indices = []\n","    sift = cv2.SIFT_create()\n","    for i, image in enumerate(image_list):\n","        if image is not None:\n","            image_np = image.numpy().transpose(1, 2, 0).astype(np.uint8)\n","            _, descriptor = sift.detectAndCompute(image_np, None)\n","            if descriptor is not None:\n","                descriptors.append(descriptor)\n","                valid_indices.append(i)\n","        else:\n","            print(\"Image is none\")\n","\n","    return descriptors, valid_indices"],"metadata":{"trusted":true,"id":"e9-XFMYXVGqq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create BOW dictionary with k-means applied on SIFT descriptors to compute centroids\n","# G is the number of words in the vocaboulary\n","def bow_dictionary(descriptors, G):\n","    bow_dict = []\n","\n","    kmeans = KMeans(n_clusters = G)\n","    kmeans.fit(descriptors)\n","\n","    bow_dict = kmeans.cluster_centers_\n","\n","    if not os.path.isfile('bow_dictionary.pkl'):\n","        pickle.dump(bow_dict, open('bow_dictionary.pkl', 'wb'))\n","\n","    return bow_dict"],"metadata":{"trusted":true,"id":"qDuP3cDRVGqs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# extract BoW features (histograms)\n","def bow_features(descriptors, centers, G):\n","    bow_features = []\n","    for descriptor_set in descriptors:\n","        for descriptor in descriptor_set:\n","            if descriptor is not None:\n","                features = np.zeros(G)\n","                distance = cdist(descriptor, centers)\n","                minimum = np.argmin(distance, axis=1)\n","                for index in minimum:\n","                    features[index] += 1\n","                bow_features.append(features)\n","            else:\n","                print(\"Null descriptor\")\n","    return bow_features"],"metadata":{"trusted":true,"id":"5i0N1-FnVGqt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# extract BoW features from training images\n","import sklearn\n","from sklearn.model_selection import GridSearchCV\n","\n","all_train_descriptors = []\n","training_descriptors = []\n","training_labels = []\n","valid_indices_all = []\n","\n","for i, data in enumerate(train_loader, 0):\n","    data_train, train_labels = data\n","    train_descriptors, valid_indices = sift_features(data_train)\n","    training_descriptors.append(train_descriptors)\n","    training_labels.extend(train_labels[valid_indices])\n","    valid_indices_all.extend(valid_indices)\n","    for descriptor in train_descriptors:\n","        if descriptor is not None:\n","            all_train_descriptors.extend(descriptor)"],"metadata":{"trusted":true,"id":"aEzFilUxVGqu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["G = 380\n","bow_dict_train = bow_dictionary(all_train_descriptors, G)\n","train_features = bow_features(training_descriptors, bow_dict_train, G)"],"metadata":{"trusted":true,"id":"xEzuSGVBVGqv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# GRID SEARCH: 5 folds cv\n","svm_model = sklearn.svm.SVC()\n","parameters = [{'C': [20, 25, 30, 35, 40, 45], 'kernel' : ['rbf', 'poly']}]\n","grid_search = GridSearchCV(estimator = svm_model, param_grid = parameters, scoring = 'accuracy', cv = 5)\n","training_labels = [tensor.item() for tensor in training_labels]\n","Y_train = training_labels\n","grid_search.fit(train_features, Y_train)"],"metadata":{"trusted":true,"id":"NpBUx1NgVGqw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Optimal parameters: \", grid_search.best_params_)"],"metadata":{"trusted":true,"id":"ikRPWOdlVGqx"},"execution_count":null,"outputs":[]}]}