{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8802726,"sourceType":"datasetVersion","datasetId":5293846}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"colab":{"provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["# useful libraries\n","import numpy as np\n","import pandas as pd\n","import os\n","import torchvision.datasets\n","from torch.utils.data import DataLoader\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","import torch.optim as optim\n","from PIL import Image\n","from torch.optim.lr_scheduler import CosineAnnealingLR"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"id":"csKtALc2VNsX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# GPU check\n","train_on_gpu = torch.cuda.is_available()\n","if not train_on_gpu:\n","    print('CUDA is not available.  Training on CPU ...')\n","else:\n","    print('CUDA is available!  Training on GPU ...')\n","device = torch.device(\"cuda:0\" if train_on_gpu else \"cpu\")\n","print(device)"],"metadata":{"trusted":true,"id":"2A9X3GUsVNsa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# creation of the training set of resized images\n","size = 128\n","\n","fake_transforms = torchvision.transforms.Compose([\n","        torchvision.transforms.ToTensor(),\n","        torchvision.transforms.Resize((size, size))\n","    ])\n","\n","\n","fake_training_set = torchvision.datasets.ImageFolder(root='/kaggle/input/supervised-sets/processedData/processedData/processed_train_set', transform=fake_transforms)\n","# create a \"fake\" loader in order to compute mean and std for normalization\n","fake_train_loader = DataLoader(fake_training_set, batch_size=64, shuffle=True, num_workers=2)"],"metadata":{"trusted":true,"id":"4o_Ce30aVNsb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# compute the mean and standard deviation for the normalization\n","def tot_mean_std(loader):\n","    mean = 0\n","    std = 0\n","    count = 0\n","    for batch,_ in loader:\n","        batch_samples = batch.size(0)\n","        batch = batch.view(batch_samples, batch.size(1), -1)\n","        # reshape to [batch_samples,3,128*128]: ready to go into the CNN\n","        mean = mean + batch.mean(2).sum(0) # mean over the pixels of each image of the batch summed to the others\n","        std = std + batch.std(2).sum(0) # same for the standard deviation\n","        count = count + batch_samples\n","\n","    mean = mean/count\n","    std = std/count\n","\n","    return mean, std"],"metadata":{"trusted":true,"id":"hDJsOKxUVNsc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["size = 128\n","mean, std = tot_mean_std(fake_train_loader)\n","#print(mean)\n","#print(std)\n","\n","transforms = torchvision.transforms.Compose([\n","        torchvision.transforms.ToTensor(),\n","        torchvision.transforms.Resize((size, size)),\n","        torchvision.transforms.Normalize(mean = mean, std = std)\n","    ])\n","\n","\n","training_set = torchvision.datasets.ImageFolder(root='/kaggle/input/supervised-sets/processedData/processedData/processed_train_set', transform=transforms)\n","validation_set = torchvision.datasets.ImageFolder(root='/kaggle/input/supervised-sets/processedData/processedData/processed_val_set', transform=transforms)\n","\n","# \"true\" loaders\n","train_loader = DataLoader(training_set, batch_size=64, shuffle=True, num_workers=2)\n","val_loader = DataLoader(validation_set, batch_size=64, shuffle=True, num_workers=2)"],"metadata":{"trusted":true,"id":"F6f1_SCXVNsd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# particular transforms for the test set, including the conversion to RGB (already made for training and validation during the preprocessing)\n","mean, std = tot_mean_std(fake_train_loader)\n","transforms_test = torchvision.transforms.Compose([\n","        torchvision.transforms.Lambda(lambda image: image.convert('RGB')),\n","        torchvision.transforms.ToTensor(),\n","        torchvision.transforms.Resize((size, size)),\n","        torchvision.transforms.Normalize(mean = mean, std = std)\n","    ])\n","\n","test_set = torchvision.datasets.ImageFolder(root='/kaggle/input/supervised-sets/processedData/processedData/processed_test_set', transform=transforms_test)\n","test_loader = DataLoader(test_set, batch_size = 1, shuffle=True, num_workers=2)"],"metadata":{"trusted":true,"id":"oAjDytlnVNse"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ID for each test class (because they are not sorted in the folders)\n","test_classes_id = [int(x) for x in list(test_set.class_to_idx)]\n","test_classes_id = np.array(test_classes_id)"],"metadata":{"trusted":true,"id":"HmesYFxXVNsf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# CNN definition\n","class Net(nn.Module):\n","\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        # output_size = (input_size - kernel_size + 2*padding_size)/stride + 1\n","        self.conv1 = nn.Conv2d(3,8,kernel_size = 5, padding = 1)  # First convolutional layer\n","        self.pool = nn.MaxPool2d(3,2)  # Max pooling layer\n","        self.conv2 = nn.Conv2d(8,12,kernel_size = 4, padding = 1)  # Second convolutional layer\n","        self.conv3 = nn.Conv2d(12,16,kernel_size = 3, padding = 1)  # Third convolutional layer\n","        self.conv4 = nn.Conv2d(16,30,kernel_size = 2, padding = 1)  # Fourth convolutional layer\n","        self.fc1 = nn.Linear(1470,550)  # First fully-connected layer\n","        self.fc2 = nn.Linear(550,251) # Output layer\n","        self.drop1 = nn.Dropout(0.5) # Dropout\n","\n","    def forward(self, x):\n","        # alternative: leaky relu\n","        x = self.pool(F.leaky_relu(self.conv1(x)))  # First convolutional layer with leaky ReLU activation and pooling\n","        x = self.pool(F.leaky_relu(self.conv2(x)))  # Second convolutional layer with leaky ReLU activation and pooling\n","        x = self.pool(F.leaky_relu(self.conv3(x)))  # Third convolutional layer with leaky ReLU activation and pooling\n","        x = self.pool(F.leaky_relu(self.conv4(x))) # Fourth convolutional layer with leaky ReLU activation and pooling\n","        x = x.view(x.shape[0],-1)  # Flatten the output from convolutional layers\n","        x = self.drop1(F.leaky_relu(self.fc1(x)))  # First fully-connected layer with leaky ReLU activation\n","        x = (self.fc2(x))  # Output layer\n","        return x\n","\n","net = Net()\n","net.to(device)"],"metadata":{"trusted":true,"id":"8TI1deBuVNsf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# SUMMARY AND NUMBER OF PARAMETERS\n","!pip install torchsummary\n","from torchsummary import summary\n","summary(net, input_size= (3,128,128))"],"metadata":{"trusted":true,"id":"djUrrh1tVNsg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# RECEPTIVE FIELD (WITHOUT DROPOUT)\n","#!git clone https://github.com/Fangyh09/pytorch-receptive-field.git\n","#!mv -v pytorch-receptive-field/torch_receptive_field ./\n","#from torch_receptive_field import receptive_field\n","\n","#receptive_field(net, input_size=(3, 128, 128))"],"metadata":{"trusted":true,"id":"o5ZK8Hy9VNsh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Number of epochs\n","epochs = 15\n","# Loss function\n","criterion = nn.CrossEntropyLoss()  # Use cross-entropy loss for multi-class classification\n","# Optimizer\n","optimizer = optim.SGD(net.parameters(), lr = 0.01, momentum=0.9)\n","# Scheduler\n","scheduler1 = CosineAnnealingLR(optimizer,T_max=epochs,  # Max number of iterations for scheduler\n","eta_min=1e-8)  # Min learning rate for scheduler"],"metadata":{"trusted":true,"id":"sxrdmTnMVNsi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TRAINING AND VALIDATION PHASE\n","best_model = None\n","record_loss = [] # record the validation losses\n","\n","avg_losses=[] # used for the final plot\n","validation_errors = [] # used for the final plot\n","\n","# Loop over the dataset multiple times (epochs)\n","for epoch in range(epochs):\n","    running_loss=[]  # track the total loss for this epoch\n","\n","    net.train() # training mode (dropout used)\n","\n","    # Iterate over the training data loader\n","    for i, data in enumerate(train_loader, 0):\n","        # Get the inputs (images) and labels from the current batch\n","        inputs, labels = data\n","\n","        # Move the inputs and labels to the device\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        # Clear the gradients accumulated in the previous iteration\n","        optimizer.zero_grad()\n","\n","\n","        outputs = net(inputs)  # Forward pass\n","        # Pass the input images through the network to get predictions\n","        loss = criterion(outputs, labels)  # Compute the loss\n","        loss.backward()  # Backpropagation\n","        optimizer.step()  # Update the weights and biases of the network based on the calculated gradients\n","        running_loss.append(loss.item())  # Accumulate the loss for this mini-batch\n","\n","    #Scheduler step\n","    scheduler1.step()\n","\n","    print('[%d] loss: %.4f' %(epoch + 1, np.mean(running_loss)))\n","    avg_losses.append(np.mean(running_loss))\n","\n","    # Validation set loop\n","    val_running_loss = []  # store validation loss for each batch\n","\n","    net.eval() # evaluation mode\n","\n","    for i, data in enumerate(val_loader):\n","        # Get inputs and labels from the data loader\n","        inputs, labels = data\n","\n","\n","        inputs = inputs.to(device)  # Move data to the specified device\n","        labels = labels.to(device)  # Move labels to the specified device\n","\n","        # Forward pass with gradient suppression\n","        with torch.no_grad():\n","            outputs = net(inputs)  # Get model predictions without calculating gradients\n","\n","        loss = criterion(outputs.squeeze(), labels.squeeze())\n","        val_running_loss.append(loss.item())\n","\n","    # Calculate and print validation performance metrics\n","    print('Validation loss: %.6f' % (np.mean(val_running_loss)))\n","    validation_errors.append(np.mean(val_running_loss))\n","\n","    if(best_model is None or np.mean(val_running_loss)< min(record_loss)): # save the model only if the mean of the current val loss is better than the previous\n","        print(f\"best model updated at epoch {epoch+1}\")\n","        best_model = net\n","        torch.save(net.state_dict(), 'best_model.pth')\n","        record_loss.append( np.mean(val_running_loss))\n"],"metadata":{"trusted":true,"id":"dUp7QbNoVNsj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib\n","import matplotlib.pyplot as plt\n","# Plotting both training and validation losses in one graph\n","epochs_x = range(1, len(avg_losses) + 1)\n","plt.plot(epochs_x, avg_losses, label='Training Loss')\n","plt.plot(epochs_x, validation_errors, label='Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.title('Training and Validation Loss')\n","plt.show()"],"metadata":{"trusted":true,"id":"Mhpfuxj3VNsj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TESTING PHASE\n","correct = 0\n","total = 0\n","labelsTest = [] # true labels\n","predictions = [] # predicted classes\n","\n","net.eval() # evaluation mode\n","\n","# Disable gradient calculation\n","with torch.no_grad():\n","    # Loop over the test loader\n","    for data in test_loader:\n","        # Get the image and label from the current batch\n","        inputs, labels = data\n","\n","        labelsTest.append(labels.cpu())\n","\n","        # Move the image data to the specified device\n","        inputs = inputs.to(device)\n","\n","        # Get the network's prediction for each image\n","        outputs = net(inputs)\n","\n","        # Find the class with the highest probability\n","        _, predicted = torch.max(outputs.cpu(), 1)\n","\n","        predictions.append(predicted.cpu())\n","\n","        # Update total number of test images\n","        total += labels.size(0)\n","\n","        # Count correct predictions\n","        correct += (predicted == labels).sum().item()\n","\n","# Compute and print accuracy\n","print('Accuracy of the network on the test images: %d %%' % (\n","    100 * correct / total))\n"],"metadata":{"trusted":true,"id":"uSCDkf5KVNsk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# true labels taken from iFood19 info\n","trainLabels = pd.read_csv('/kaggle/input/supervised-sets/train_labels.csv')\n","testLabels = pd.read_csv('//kaggle/input/supervised-sets/val_labels.csv')\n","\n","trainClasses = trainLabels['label'].unique()\n","testClasses = testLabels['label'].unique()"],"metadata":{"trusted":true,"id":"ifMl9s1tVNsl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# number of samples per class in the test set\n","n = []\n","testClasses = np.sort(testClasses)\n","for i in testClasses:\n","    matching_rows = testLabels[testLabels['label'] == i]\n","    n.append(len(matching_rows))"],"metadata":{"trusted":true,"id":"wh5dcqD4VNsl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Percentages of correctly classified samples in the test set for each class\n","# The fact that the folders are not sorted per class is taken into account by the class id\n","k = 0\n","for i in range(0,251):\n","    corr = 0\n","    for j in range(0,len(test_loader)):\n","        if((labelsTest[j].item() == predictions[j].item()) & (labelsTest[j].item() == (np.where(test_classes_id == i)[0][0]))):\n","            corr = corr + 1\n","    if(int(corr/n[i]*100) > 0):\n","        print(\"Correctly classified samples for class\", i)\n","        print(int((corr/n[i])*100),\"%\")\n","        k = k+1\n","print(\"Number of classes with non zero percentage of correctly classified samples\")\n","print(k)"],"metadata":{"trusted":true,"id":"6BLiSpYbVNsm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Confusion matrix for two specific classes\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix\n","import matplotlib as mp\n","\n","\n","ls = []\n","preds = []\n","\n","for j in range(0,len(test_loader)):\n","    if(((labelsTest[j].item() == (np.where(test_classes_id == 12)[0][0])) | (labelsTest[j].item() == (np.where(test_classes_id == 148)[0][0]))) & ((predictions[j].item() == (np.where(test_classes_id == 12)[0][0])) | (predictions[j].item() == (np.where(test_classes_id == 148)[0][0])))):\n","        ls.append(labelsTest[j].item())\n","        preds.append(predictions[j].item())\n","\n","\n","conf_matr = confusion_matrix(ls, preds)\n","ax = sns.heatmap(conf_matr, annot=True, cmap='Oranges')\n","ax.set_title('Confusion Matrix for Test set \\n\\n');\n","ax.set_xlabel('\\nPredicted Values')\n","ax.set_ylabel('Actual Values ');\n","mp.pyplot.show()\n","mp.pyplot.clf()"],"metadata":{"trusted":true,"id":"iYrxUXdoVNsm"},"execution_count":null,"outputs":[]}]}